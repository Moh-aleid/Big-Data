{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Base URLs\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "first_page_url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
        "\n",
        "\n",
        "# Send a GET request to fetch the webpage\n",
        "response = requests.get(first_page_url)\n",
        "\n",
        "# Display the HTML source code\n",
        "print(\"=== HTML Source Code of the Page ===\\n\")\n",
        "print(response.text[:1000])  # Print only the first 2000 characters (for readability)\n",
        "print(\"\\n=== End of HTML Source Code ===\\n\")\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Detect total pages automatically\n",
        "page_text = soup.find(\"li\", class_=\"current\").text.strip()  # \"Page 1 of 50\"\n",
        "total_pages = int(page_text.split(\"of\")[-1].strip())\n",
        "print(f\"ðŸ“„ Total pages found: {total_pages}\")\n",
        "\n",
        "# Create CSV file\n",
        "with open(\"books.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Title\", \"Price\", \"Availability\", \"Product_URL\"])\n",
        "\n",
        "    # Loop through all detected pages\n",
        "    for page in range(1, total_pages + 1):\n",
        "        print(f\"Scraping page {page}/{total_pages}...\")\n",
        "        url = base_url.format(page)\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Find all book containers\n",
        "        books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "\n",
        "        for book in books:\n",
        "            title = book.h3.a[\"title\"]\n",
        "            price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
        "            availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "            product_link = \"https://books.toscrape.com/catalogue/\" + book.h3.a[\"href\"]\n",
        "\n",
        "            # Write row directly (no extra request)\n",
        "            writer.writerow([title, price, availability, product_link])\n",
        "\n",
        "print(\"Done! Data saved to 'books.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxz5gYsE-vcE",
        "outputId": "3eae6721-1b3b-4ffe-c0ee-67325d880d8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== HTML Source Code of the Page ===\n",
            "\n",
            "\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
            "<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
            "<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\n",
            "<!--[if gt IE 8]><!--> <html lang=\"en-us\" class=\"no-js\"> <!--<![endif]-->\n",
            "    <head>\n",
            "        <title>\n",
            "    All products | Books to Scrape - Sandbox\n",
            "</title>\n",
            "\n",
            "        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\n",
            "        <meta name=\"created\" content=\"24th Jun 2016 09:30\" />\n",
            "        <meta name=\"description\" content=\"\" />\n",
            "        <meta name=\"viewport\" content=\"width=device-width\" />\n",
            "        <meta name=\"robots\" content=\"NOARCHIVE,NOCACHE\" />\n",
            "\n",
            "        <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->\n",
            "        <!--[if lt IE 9]>\n",
            "        <script src=\"//html5shim.googlecode.com/svn/trunk/html5.js\"></script>\n",
            "        <![endif]-->\n",
            "\n",
            "        \n",
            "            <link rel=\"shortcut icon\" href=\"../static/oscar/fav\n",
            "\n",
            "=== End of HTML Source Code ===\n",
            "\n",
            "ðŸ“„ Total pages found: 50\n",
            "Scraping page 1/50...\n",
            "Scraping page 2/50...\n",
            "Scraping page 3/50...\n",
            "Scraping page 4/50...\n",
            "Scraping page 5/50...\n",
            "Scraping page 6/50...\n",
            "Scraping page 7/50...\n",
            "Scraping page 8/50...\n",
            "Scraping page 9/50...\n",
            "Scraping page 10/50...\n",
            "Scraping page 11/50...\n",
            "Scraping page 12/50...\n",
            "Scraping page 13/50...\n",
            "Scraping page 14/50...\n",
            "Scraping page 15/50...\n",
            "Scraping page 16/50...\n",
            "Scraping page 17/50...\n",
            "Scraping page 18/50...\n",
            "Scraping page 19/50...\n",
            "Scraping page 20/50...\n",
            "Scraping page 21/50...\n",
            "Scraping page 22/50...\n",
            "Scraping page 23/50...\n",
            "Scraping page 24/50...\n",
            "Scraping page 25/50...\n",
            "Scraping page 26/50...\n",
            "Scraping page 27/50...\n",
            "Scraping page 28/50...\n",
            "Scraping page 29/50...\n",
            "Scraping page 30/50...\n",
            "Scraping page 31/50...\n",
            "Scraping page 32/50...\n",
            "Scraping page 33/50...\n",
            "Scraping page 34/50...\n",
            "Scraping page 35/50...\n",
            "Scraping page 36/50...\n",
            "Scraping page 37/50...\n",
            "Scraping page 38/50...\n",
            "Scraping page 39/50...\n",
            "Scraping page 40/50...\n",
            "Scraping page 41/50...\n",
            "Scraping page 42/50...\n",
            "Scraping page 43/50...\n",
            "Scraping page 44/50...\n",
            "Scraping page 45/50...\n",
            "Scraping page 46/50...\n",
            "Scraping page 47/50...\n",
            "Scraping page 48/50...\n",
            "Scraping page 49/50...\n",
            "Scraping page 50/50...\n",
            "Done! Data saved to 'books.csv'\n"
          ]
        }
      ]
    }
  ]
}